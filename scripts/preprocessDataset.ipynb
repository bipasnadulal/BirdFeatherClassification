{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Preprocessing dataset by optimizing memory and also saving the preprocessed data into the directory preprocessed_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The following code is for preprocessing data  batch wise and saving them in each directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Done the preprocessing with this code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Define dataset paths\n",
    "train_dir = \"D:/BirdFeatherClassification/dataset/split_data/train\"\n",
    "val_dir = \"D:/BirdFeatherClassification/dataset/split_data/val\"\n",
    "test_dir = \"D:/BirdFeatherClassification/dataset/split_data/test\"\n",
    "\n",
    "# Define preprocessing parameters\n",
    "IMG_SIZE = (128, 128)  \n",
    "BATCH_SIZE = 16\n",
    "\n",
    "# Function to load and preprocess images\n",
    "def load_image(image_path, label):\n",
    "    \"\"\"Load an image, decode it, resize, normalize, and handle errors.\"\"\"\n",
    "    img = tf.io.read_file(image_path)\n",
    "    \n",
    "    # Try decoding different image formats\n",
    "    try:\n",
    "        img = tf.image.decode_jpeg(img, channels=3)  # Try JPEG first\n",
    "    except:\n",
    "        try:\n",
    "            img = tf.image.decode_png(img, channels=3)  # Try PNG\n",
    "        except:\n",
    "            try:\n",
    "                img = tf.image.decode_bmp(img, channels=3)  # Try BMP\n",
    "            except:\n",
    "                try:\n",
    "                    img = tf.image.decode_gif(img)  # Try GIF\n",
    "                    img = img[0]  # Extract first frame if GIF\n",
    "                except:\n",
    "                    print(f\"Skipping unsupported or corrupted image: {image_path.numpy().decode()}\")\n",
    "                    return tf.zeros(IMG_SIZE + (3,)), -1  # Return dummy image & invalid label\n",
    "    \n",
    "    img = tf.image.resize(img, IMG_SIZE)  # Resize image\n",
    "    img = img / 255.0  # Normalize pixel values to [0, 1]\n",
    "    return img, label\n",
    "\n",
    "# Function to create a dataset from a directory\n",
    "def create_dataset(directory):\n",
    "    \"\"\"Create a TensorFlow dataset from a directory of images.\"\"\"\n",
    "    class_names = sorted(os.listdir(directory))  # Sort to maintain label consistency\n",
    "    image_paths = []\n",
    "    labels = []\n",
    "\n",
    "    for class_idx, class_name in enumerate(class_names):\n",
    "        class_path = os.path.join(directory, class_name)\n",
    "        if os.path.isdir(class_path):\n",
    "            for img_file in os.listdir(class_path):\n",
    "                img_path = os.path.join(class_path, img_file)\n",
    "                image_paths.append(img_path)\n",
    "                labels.append(class_idx)\n",
    "\n",
    "    # Convert lists to TensorFlow datasets\n",
    "    path_ds = tf.data.Dataset.from_tensor_slices(image_paths)\n",
    "    label_ds = tf.data.Dataset.from_tensor_slices(labels)\n",
    "    dataset = tf.data.Dataset.zip((path_ds, label_ds))\n",
    "    \n",
    "    # Apply image processing function\n",
    "    dataset = dataset.map(lambda path, lbl: tf.py_function(\n",
    "        func=load_image, inp=[path, lbl], Tout=(tf.float32, tf.int32)), num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "    dataset = dataset.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)  # Batch processing\n",
    "    return dataset\n",
    "\n",
    "# Load datasets\n",
    "train_dataset = create_dataset(train_dir)\n",
    "val_dataset = create_dataset(val_dir)\n",
    "test_dataset = create_dataset(test_dir)\n",
    "\n",
    "# Paths to save preprocessed datasets\n",
    "train_save_path = \"D:/BirdFeatherClassification/dataset/split_data/preprocessed_data/train\"\n",
    "val_save_path = \"D:/BirdFeatherClassification/dataset/split_data/preprocessed_data/val\"\n",
    "test_save_path = \"D:/BirdFeatherClassification/dataset/split_data/preprocessed_data/test\"\n",
    "\n",
    "# Function to save dataset in batches\n",
    "def save_batches(dataset, save_path, dataset_type):\n",
    "    \"\"\"Save dataset batches as compressed .npz files.\"\"\"\n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "    batch_index = 0\n",
    "    for batch_images, batch_labels in dataset:\n",
    "        valid_indices = tf.where(batch_labels != -1)[:, 0]  # Ignore invalid images\n",
    "        batch_images = tf.gather(batch_images, valid_indices)\n",
    "        batch_labels = tf.gather(batch_labels, valid_indices)\n",
    "\n",
    "        if len(batch_images) > 0:  # Save only if valid images exist\n",
    "            np.savez_compressed(os.path.join(save_path, f\"{dataset_type}_batch_{batch_index}.npz\"),\n",
    "                                images=batch_images.numpy(), labels=batch_labels.numpy())\n",
    "            batch_index += 1\n",
    "\n",
    "# Save train, validation, and test datasets\n",
    "save_batches(train_dataset, train_save_path, \"train\")\n",
    "save_batches(val_dataset, val_save_path, \"val\")\n",
    "save_batches(test_dataset, test_save_path, \"test\")\n",
    "\n",
    "print(\"Datasets successfully preprocessed and saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the path to preprocessed data\n",
    "train_dir = \"D:/BirdFeatherClassification/dataset/split_data/preprocessed_data/train\"\n",
    "val_dir = \"D:/BirdFeatherClassification/dataset/split_data/preprocessed_data/val\"\n",
    "test_dir = \"D:/BirdFeatherClassification/dataset/split_data/preprocessed_data/test\"\n",
    "\n",
    "# Function to load and display a batch of images from the preprocessed data\n",
    "def visualize_batch(batch_file_path):\n",
    "    # Load the batch data\n",
    "    data = np.load(batch_file_path)\n",
    "    images = data['images']\n",
    "    labels = data['labels']\n",
    "\n",
    "    # Display the first 5 images in the batch (you can change the number if needed)\n",
    "    num_images = min(5, len(images))\n",
    "    \n",
    "    plt.figure(figsize=(10, 10))\n",
    "    for i in range(num_images):\n",
    "        plt.subplot(1, num_images, i + 1)\n",
    "        plt.imshow(images[i])\n",
    "        plt.title(f\"Label: {labels[i]}\")\n",
    "        plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Function to load a specific batch file (e.g., the first batch in the train set)\n",
    "def load_sample_batch(directory):\n",
    "    # Get the list of batch files in the directory\n",
    "    batch_files = [f for f in os.listdir(directory) if f.endswith('.npz')]\n",
    "    \n",
    "    # Load the first batch file (or you can modify to load any batch index)\n",
    "    if batch_files:\n",
    "        sample_batch_file = os.path.join(directory, batch_files[0])  # Load the first batch file\n",
    "        visualize_batch(sample_batch_file)\n",
    "    else:\n",
    "        print(\"No batch files found in this directory!\")\n",
    "\n",
    "# Visualize a sample batch from the train, val, and test directories\n",
    "print(\"Visualizing a sample from train data:\")\n",
    "load_sample_batch(train_dir)\n",
    "\n",
    "print(\"Visualizing a sample from val data:\")\n",
    "load_sample_batch(val_dir)\n",
    "\n",
    "print(\"Visualizing a sample from test data:\")\n",
    "load_sample_batch(test_dir)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
